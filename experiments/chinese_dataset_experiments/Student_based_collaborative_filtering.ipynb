{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006f4b96-d620-40e2-a9ef-80c4b9950848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import recommendations\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64b30f7-227d-441f-9e18-f8045d40cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../datasets/ANHUI/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5332968-b3e9-4d75-901c-65c6d8778ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Number</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Department Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ideological and Moral Cultivation and Legal Fo...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Success: Career Planning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Introduction to Computer Science</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Advanced Mathematics A(1)</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>College English A(1)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>381</td>\n",
       "      <td>J2EE Framework</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>381</td>\n",
       "      <td>Intellectual Property and Software Protection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>381</td>\n",
       "      <td>Human-Computer Interaction Technology</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>381</td>\n",
       "      <td>Software Development and Testing Training</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>381</td>\n",
       "      <td>Python Language Programming</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student Number                                       Course Title  \\\n",
       "0                   0  Ideological and Moral Cultivation and Legal Fo...   \n",
       "1                   0                           Success: Career Planning   \n",
       "2                   0                   Introduction to Computer Science   \n",
       "3                   0                          Advanced Mathematics A(1)   \n",
       "4                   0                               College English A(1)   \n",
       "...               ...                                                ...   \n",
       "19095             381                                     J2EE Framework   \n",
       "19096             381      Intellectual Property and Software Protection   \n",
       "19097             381              Human-Computer Interaction Technology   \n",
       "19098             381          Software Development and Testing Training   \n",
       "19099             381                        Python Language Programming   \n",
       "\n",
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit Department Code  \n",
       "0          3.102564             19.5             BLG  \n",
       "1          3.102564             19.5             BLG  \n",
       "2          3.102564             19.5             BLG  \n",
       "3          3.102564             19.5             BLG  \n",
       "4          3.102564             19.5             BLG  \n",
       "...             ...              ...             ...  \n",
       "19095      2.800000             20.0             BLG  \n",
       "19096      3.625000              8.0             BLG  \n",
       "19097      3.625000              8.0             BLG  \n",
       "19098      3.625000              8.0             BLG  \n",
       "19099      3.625000              8.0             BLG  \n",
       "\n",
       "[19100 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc727c7f-d1a2-4685-9f3e-4a108550f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Department Code'], prefix='Department Code')], axis=1)\n",
    "df.drop(['Department Code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480cf2a3-30da-4557-a5d5-c46d9e9508f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Number</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Department Code_BLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ideological and Moral Cultivation and Legal Fo...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Success: Career Planning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Introduction to Computer Science</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Advanced Mathematics A(1)</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>College English A(1)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>381</td>\n",
       "      <td>J2EE Framework</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>381</td>\n",
       "      <td>Intellectual Property and Software Protection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>381</td>\n",
       "      <td>Human-Computer Interaction Technology</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>381</td>\n",
       "      <td>Software Development and Testing Training</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>381</td>\n",
       "      <td>Python Language Programming</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student Number                                       Course Title  \\\n",
       "0                   0  Ideological and Moral Cultivation and Legal Fo...   \n",
       "1                   0                           Success: Career Planning   \n",
       "2                   0                   Introduction to Computer Science   \n",
       "3                   0                          Advanced Mathematics A(1)   \n",
       "4                   0                               College English A(1)   \n",
       "...               ...                                                ...   \n",
       "19095             381                                     J2EE Framework   \n",
       "19096             381      Intellectual Property and Software Protection   \n",
       "19097             381              Human-Computer Interaction Technology   \n",
       "19098             381          Software Development and Testing Training   \n",
       "19099             381                        Python Language Programming   \n",
       "\n",
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Department Code_BLG  \n",
       "0          3.102564             19.5                 True  \n",
       "1          3.102564             19.5                 True  \n",
       "2          3.102564             19.5                 True  \n",
       "3          3.102564             19.5                 True  \n",
       "4          3.102564             19.5                 True  \n",
       "...             ...              ...                  ...  \n",
       "19095      2.800000             20.0                 True  \n",
       "19096      3.625000              8.0                 True  \n",
       "19097      3.625000              8.0                 True  \n",
       "19098      3.625000              8.0                 True  \n",
       "19099      3.625000              8.0                 True  \n",
       "\n",
       "[19100 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c7ab4f-ca25-4d89-a91a-f90834416c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_credits = {}\n",
    "for row_idx in df.index:\n",
    "    course_title = df.iloc[row_idx, 1]\n",
    "    credit = df.iloc[row_idx, 2]    \n",
    "    course_credits[course_title] = credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9fa0f7-f333-497b-8776-a9e2d11638ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semester_data(semester_num):\n",
    "    semester_data = {}   # semester data in shape {student_number: {course_title: grade, ...}, ...}\n",
    "    \n",
    "    # extracting the instances with the given semester_num from the main dataFrame\n",
    "    dataset = df[df.iloc[:, 4] == semester_num]\n",
    "    dataset.index = range(len(dataset)) \n",
    "\n",
    "    # filling the semester_data dictionary\n",
    "    for row_idx in dataset.index:\n",
    "        student_number = dataset.iloc[row_idx, 0]\n",
    "        course_title = dataset.iloc[row_idx, 1]\n",
    "        grade = dataset.iloc[row_idx, 3]\n",
    "        \n",
    "        semester_data.setdefault(student_number, {})\n",
    "        semester_data[student_number][course_title] = grade\n",
    "    \n",
    "    return semester_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d1c866-b7cc-4a4f-9bba-7e891700f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_gpa(train_semester, student):\n",
    "    courses = train_semester[student]\n",
    "    total_credit = 0\n",
    "    weights = 0\n",
    "    for course in courses:\n",
    "        total_credit += course_credits[course]\n",
    "        weights += courses[course] * course_credits[course]\n",
    "    \n",
    "    return weights / total_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a598770a-d8b1-4112-8d95-f75d436ea90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grade_stats(semester_data, student):\n",
    "    grade_list = []\n",
    "    \n",
    "    for course in semester_data[student]:\n",
    "        grade = semester_data[student][course]\n",
    "        grade_list.append(grade)\n",
    "    \n",
    "    mean = np.mean(grade_list)\n",
    "    std_dev = np.std(grade_list)\n",
    "    \n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12825e1a-ab71-4fd0-bb47-1f805c2a2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cluster(train_sems, num_clusters, training_data, cluster_model):\n",
    "\n",
    "    train_dataset = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # extracting instances from the dataset which should be in training data\n",
    "    for sem in train_sems:\n",
    "        train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n",
    " \n",
    "    cluster_features = train_dataset[['GPA', 'Completed Credits'] + list(train_dataset.columns[9:])]\n",
    "    \n",
    "    # fitting a clustering model based on GPA, Completed Credits and Departments\n",
    "    fitted_cluster_model = cluster_model(n_clusters=num_clusters).fit(cluster_features)\n",
    "    cluster_labels = fitted_cluster_model.labels_  \n",
    "    \n",
    "    cluster_dataset = {}   # splitting the train dataset into sub-dicts based on their predicted cluster label\n",
    "    \n",
    "    # assigning each students' data to their predicted clusters\n",
    "    for i in range(len(cluster_labels)):\n",
    "        cluster_dataset.setdefault(cluster_labels[i], {})\n",
    "        student_number = train_dataset.iloc[i, 0]\n",
    "        cluster_dataset[cluster_labels[i]][student_number] = training_data[student_number]\n",
    "    \n",
    "    return cluster_dataset, fitted_cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbeeb303-8b10-4701-a498-004eca0faea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_test_data(fitted_cluster_model, semester_num):\n",
    "    # extracting all instances with the given semester_num from the main dataFrame\n",
    "    test_dataset = df[df.iloc[:, 4] == semester_num]\n",
    "    test_dataset.index = range(len(test_dataset))\n",
    "    \n",
    "    # predicting the cluster labels of test data using a cluster model fitted on the train data so far\n",
    "    cluster_features = test_dataset[['GPA', 'Completed Credits'] + list(test_dataset.columns[9:])]\n",
    "    cluster_labels = fitted_cluster_model.predict(cluster_features) # predict the test data \n",
    "    \n",
    "    # getting the semester data of available students in test semester\n",
    "    semester_data = get_semester_data(semester_num)\n",
    "    \n",
    "    cluster_dataset = {}   # splitting the test dataset into sub-dicts based on their predicted cluster label\n",
    "    \n",
    "    # assigning each students' data to their predicted clusters\n",
    "    for i in range(len(cluster_labels)):\n",
    "        cluster_dataset.setdefault(cluster_labels[i], {})\n",
    "        student_number = test_dataset.iloc[i, 0]\n",
    "        cluster_dataset[cluster_labels[i]][student_number] = semester_data[student_number]\n",
    "        \n",
    "    return cluster_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776cfb85-d26d-4b2e-a0d8-79476938c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(train_semester, test_semester, sim, item_based):\n",
    "    # print(f\"train_semester: {train_semester}\")\n",
    "    average_gpa = {}\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    gpa = {}\n",
    "    \n",
    "    for student in train_semester:\n",
    "        # print(f'student: {student}')\n",
    "        gpa[student] = get_avg_gpa(train_semester, student)\n",
    "    \n",
    "    item_sims = recommendations.calculateSimilarItems(train_semester)\n",
    "    # predicting recommended courses for each student in training data\n",
    "    for student in train_semester:\n",
    "        # print(f'{student} student')\n",
    "        recommended_courses = {}\n",
    "        \n",
    "        if item_based:\n",
    "            recs = recommendations.getRecommendedItems(train_semester, item_sims, student)\n",
    "        else:\n",
    "            # print('somthing')\n",
    "            recs = recommendations.getRecommendations(train_semester, student, sim, dgpa=True, gpa=gpa, delta=0.7)\n",
    "        \n",
    "        # print(f'recs {recs}')\n",
    "\n",
    "        for rec_grade, rec_course in recs:\n",
    "            # print(f'recs: {recs}')\n",
    "            recommended_courses.setdefault(rec_course, rec_grade)\n",
    "            \n",
    "        average_gpa.setdefault(student, get_avg_gpa(train_semester, student))\n",
    "        \n",
    "        # skipping students from training data who do not have not taken courses in test data\n",
    "        if student not in test_semester:\n",
    "            continue\n",
    "        \n",
    "        mean, std_dev = get_grade_stats(train_semester, student)\n",
    "\n",
    "       # checking for students' test data records in recommended courses\n",
    "        for course_title in test_semester[student]:\n",
    "            # print(f\"Course: {course_title}, Recommended Courses: {recommended_courses}\")\n",
    "            if course_title in recommended_courses:   # considering the predicted grade if course is available\n",
    "                rec_grade = recommended_courses[course_title]\n",
    "                if rec_grade < mean - (2 * std_dev) or rec_grade > mean + (2 * std_dev):\n",
    "                    continue\n",
    "                y_pred.append(rec_grade)\n",
    "            else:   # considering the average GPA if course is not available in recommended courses\n",
    "                rec_grade = average_gpa[student]\n",
    "                if rec_grade < mean - (2 * std_dev) or rec_grade > mean + (2 * std_dev):\n",
    "                    continue\n",
    "                y_pred.append(rec_grade)\n",
    "            y_true.append(test_semester[student][course_title])\n",
    "            \n",
    "    assert len(y_true) == len(y_pred)   \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7957aa71-a44f-4786-80da-d2fe84299e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sim, cluster_model, item_based=False):\n",
    "    predictions = {} # storing error scores in a dict with shape: \n",
    "                      # {num_clusters (k=2,3,...,7): \n",
    "                        # {num_training_semesters (N=1,2,...,7): {'y_true': [], 'y_pred': []}, ...},\n",
    "                      #...}\n",
    "    \n",
    "    sorted_semesters = sorted(set(df.iloc[:, 4]))   # sorting semesters in a time series manner\n",
    "    for num_clusters in range(10, 31, 5):\n",
    "        predictions.setdefault(str(num_clusters), {})\n",
    "        train_semester = {}   # {student_number: {course_title: grade, ...}, ...}\n",
    "        for sem_idx in range(1, len(sorted_semesters)): \n",
    "            predictions[str(num_clusters)].setdefault(str(sem_idx), {'y_true': [], 'y_pred': []})\n",
    "            \n",
    "            # combining all previous semesters in dataset and consider it as training semester\n",
    "            new_semester = get_semester_data(sorted_semesters[sem_idx-1])\n",
    "            for student in new_semester:\n",
    "                if student in train_semester:   # combine data if a student already exist\n",
    "                    train_semester[student].update(new_semester[student])\n",
    "                else:   # create a new key-value pair for students with no record\n",
    "                    train_semester[student] = new_semester[student]\n",
    "            \n",
    "            training_semesters_name = sorted_semesters[:sem_idx]   # names of all training semesters\n",
    "            print(training_semesters_name)\n",
    "            \n",
    "            # getting the cluster model fitted on training data and each clusters' training data\n",
    "            train_cluster_data, fitted_cluster_model = fit_cluster(training_semesters_name, num_clusters, train_semester, cluster_model)\n",
    "            \n",
    "            # getting the clustered test data\n",
    "            test_semester_name = sorted_semesters[sem_idx]\n",
    "            test_cluster_data = cluster_test_data(fitted_cluster_model, test_semester_name)\n",
    "            \n",
    "            # fitting each cluster label with a similarity metric, and measure the error between the same\n",
    "            # cluster labels in training and test data\n",
    "            for cluster_label in train_cluster_data:\n",
    "                if cluster_label not in test_cluster_data:\n",
    "                    continue\n",
    "                y_true, y_pred = get_errors(train_cluster_data[cluster_label], test_cluster_data[cluster_label], sim, item_based)\n",
    "                predictions[str(num_clusters)][str(sem_idx)]['y_true'] += y_true\n",
    "                predictions[str(num_clusters)][str(sem_idx)]['y_pred'] += y_pred\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62ca2c6b-a10a-4540-aad3-797fd6e6656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bea25",
   "metadata": {},
   "source": [
    "### User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e82f396c-beab-452c-a946-ce3d9f5516c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_93745/649198034.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_dataset = pd.concat([train_dataset, df[df.iloc[:, 4] == sem]], ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecommendations\u001b[49m\u001b[43m.\u001b[49m\u001b[43msim_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKMeans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m model_predictions[\u001b[33m'\u001b[39m\u001b[33mEuclidean Distance\u001b[39m\u001b[33m'\u001b[39m] = predictions\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(sim, cluster_model, item_based)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cluster_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m test_cluster_data:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m y_true, y_pred = \u001b[43mget_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_cluster_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cluster_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_based\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m predictions[\u001b[38;5;28mstr\u001b[39m(num_clusters)][\u001b[38;5;28mstr\u001b[39m(sem_idx)][\u001b[33m'\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m'\u001b[39m] += y_true\n\u001b[32m     39\u001b[39m predictions[\u001b[38;5;28mstr\u001b[39m(num_clusters)][\u001b[38;5;28mstr\u001b[39m(sem_idx)][\u001b[33m'\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m'\u001b[39m] += y_pred\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mget_errors\u001b[39m\u001b[34m(train_semester, test_semester, sim, item_based)\u001b[39m\n\u001b[32m     19\u001b[39m     recs = recommendations.getRecommendedItems(train_semester, item_sims, student)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# print('yorulduk')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     recs = \u001b[43mrecommendations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetRecommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_semester\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdgpa\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpa\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# print(f'recs {recs}')\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rec_grade, rec_course \u001b[38;5;129;01min\u001b[39;00m recs:\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# print(f'recs: {recs}')\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/predicting-student-grade-dev/experiments/chinese_dataset_experiments/recommendations.py:94\u001b[39m, in \u001b[36mgetRecommendations\u001b[39m\u001b[34m(prefs, person, similarity, dgpa, gpa, delta)\u001b[39m\n\u001b[32m     92\u001b[39m simSums = {}\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m prefs:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     sim = \u001b[43msimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dgpa:\n\u001b[32m     96\u001b[39m         student_gpa = gpa[person]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/predicting-student-grade-dev/experiments/chinese_dataset_experiments/recommendations.py:49\u001b[39m, in \u001b[36msim_distance\u001b[39m\u001b[34m(prefs, person1, person2)\u001b[39m\n\u001b[32m     47\u001b[39m         si[item]=\u001b[32m1\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(si)==\u001b[32m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m sum_of_squares = \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprefs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mperson1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mperson2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\\\n\u001b[32m     50\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m si])\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m/(\u001b[32m1\u001b[39m+sqrt(sum_of_squares))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "predictions = predict(recommendations.sim_distance, KMeans)\n",
    "model_predictions['Euclidean Distance'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fbe228-4c3d-46fd-b959-ffb92f651a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(recommendations.sim_jaccard, KMeans)\n",
    "model_predictions['Jaccard Index'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e2eaa-a51b-4d05-91be-0b8ac66b7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(recommendations.sim_pearson, KMeans)\n",
    "model_predictions['Pearson Correlation'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15395fd3-e894-483d-9f67-0235d5375379",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('student_base_clustering_and_userbased_collaborative_filtering.json', 'w') as fw:\n",
    "    json.dump(model_predictions, fw, default=str)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc70710",
   "metadata": {},
   "source": [
    "### Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926a2f07-ac8a-4870-82b8-8bd420630da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3933287",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(recommendations.sim_distance, KMeans, item_based=True)\n",
    "model_predictions['Euclidean Distance'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac02f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(recommendations.sim_jaccard, KMeans, item_based=True)\n",
    "model_predictions['Jaccard Index'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3848b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(recommendations.sim_pearson, KMeans, item_based=True)\n",
    "model_predictions['Pearson Correlation'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb00abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('student_base_clustering_and_itembased_collaborative_filtering.json', 'w') as fw:\n",
    "    json.dump(model_predictions, fw, default=str)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323e60c",
   "metadata": {},
   "source": [
    "# cf coverage ratio analizi icin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anhui Dataset - Global CF Coverage Analysis (No Clustering)...\n",
      "\n",
      "========================================\n",
      "Total Instances:     16044\n",
      "Covered by CF:       0\n",
      "COVERAGE RATIO:      0.00%  <-- BU DEĞERİ KULLAN\n",
      "----------------------------------------\n",
      "RMSE (Pure CF):      0.0000\n",
      "RMSE (Fallback):     0.9879\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import recommendations\n",
    "\n",
    "# --- YARDIMCI FONKSİYON: Global İstatistik ---\n",
    "def get_global_coverage_stats(train_semester, test_semester, is_item_based=True):\n",
    "    covered_count = 0\n",
    "    total_count = 0\n",
    "    covered_sq_err = []\n",
    "    fallback_sq_err = []\n",
    "    \n",
    "    # 1. Ortalamaları Hazırla\n",
    "    average_gpa = {}\n",
    "    for student in train_semester:\n",
    "        average_gpa[student] = get_avg_gpa(train_semester, student)\n",
    "        \n",
    "    # 2. Benzerlik Matrisi (Tüm veri üzerinde)\n",
    "    # Eğer Item-Based ise\n",
    "    item_sims = {}\n",
    "    if is_item_based:\n",
    "        # recommendations dosyanızdaki calculateSimilarItems fonksiyonu\n",
    "        # parametre alıyorsa n=10 verin, almıyorsa boş bırakın.\n",
    "        try:\n",
    "            item_sims = recommendations.calculateSimilarItems(train_semester, n=10)\n",
    "        except TypeError:\n",
    "            item_sims = recommendations.calculateSimilarItems(train_semester)\n",
    "\n",
    "    # 3. Test Aşaması\n",
    "    for student in train_semester: # Sadece geçmişi olan öğrenciler\n",
    "        if student not in test_semester:\n",
    "            continue\n",
    "            \n",
    "        # Önerileri Al\n",
    "        recommended_courses = {}\n",
    "        if is_item_based:\n",
    "            recs = recommendations.getRecommendedItems(train_semester, item_sims, student)\n",
    "        else:\n",
    "            # User-Based Pearson (Varsayılan)\n",
    "            recs = recommendations.getRecommendations(train_semester, student) # sim parametresi gerekebilir\n",
    "            \n",
    "        # Sözlüğe çevir: {Ders: Tahmin}\n",
    "        for rec_grade, rec_course in recs:\n",
    "            recommended_courses[rec_course] = rec_grade\n",
    "            \n",
    "        # Outlier kontrolü için istatistik\n",
    "        mean, std_dev = get_grade_stats(train_semester, student)\n",
    "\n",
    "        # Hedef dersleri kontrol et\n",
    "        for course_title in test_semester[student]:\n",
    "            actual_grade = test_semester[student][course_title]\n",
    "            total_count += 1\n",
    "            \n",
    "            pred_grade = 0\n",
    "            is_covered = False\n",
    "            \n",
    "            # --- KRİTİK KONTROL ---\n",
    "            if course_title in recommended_courses:\n",
    "                pred_grade = recommended_courses[course_title]\n",
    "                is_covered = True\n",
    "            else:\n",
    "                pred_grade = average_gpa.get(student, 0)\n",
    "                is_covered = False\n",
    "                \n",
    "            # Outlier Filtresi (Coverage hesabını bozmaması için buraya da ekliyoruz)\n",
    "            if std_dev > 0:\n",
    "                if pred_grade < mean - (2 * std_dev) or pred_grade > mean + (2 * std_dev):\n",
    "                    continue # Tahmin geçersiz sayılır, pas geç\n",
    "            \n",
    "            # Hata Kaydı\n",
    "            err_sq = (pred_grade - actual_grade) ** 2\n",
    "            if is_covered:\n",
    "                covered_count += 1\n",
    "                covered_sq_err.append(err_sq)\n",
    "            else:\n",
    "                fallback_sq_err.append(err_sq)\n",
    "\n",
    "    return covered_sq_err, fallback_sq_err\n",
    "\n",
    "# --- ANA ÇALIŞTIRMA (NO CLUSTERING) ---\n",
    "def analyze_anhui_global_coverage():\n",
    "    print(\"Anhui Dataset - Global CF Coverage Analysis (No Clustering)...\")\n",
    "    \n",
    "    all_covered = []\n",
    "    all_fallback = []\n",
    "    \n",
    "    sorted_semesters = sorted(set(df.iloc[:, 4]))\n",
    "    \n",
    "    for sem_idx in range(1, len(sorted_semesters)):\n",
    "        curr_sem_name = sorted_semesters[sem_idx]\n",
    "        # print(f\"Processing {curr_sem_name}...\")\n",
    "        \n",
    "        # Train verisini kümülatif hazırla\n",
    "        train_semester = {}\n",
    "        for k in range(sem_idx):\n",
    "             sem_data = get_semester_data(sorted_semesters[k])\n",
    "             for stu in sem_data:\n",
    "                 if stu in train_semester:\n",
    "                     train_semester[stu].update(sem_data[stu])\n",
    "                 else:\n",
    "                     train_semester[stu] = sem_data[stu].copy()\n",
    "        \n",
    "        test_semester = get_semester_data(curr_sem_name)\n",
    "        \n",
    "        # Kümeleme yapmadan direkt hesapla\n",
    "        cov_sq, fb_sq = get_global_coverage_stats(train_semester, test_semester, is_item_based=True)\n",
    "        \n",
    "        all_covered.extend(cov_sq)\n",
    "        all_fallback.extend(fb_sq)\n",
    "        \n",
    "    # --- RAPOR ---\n",
    "    total_valid = len(all_covered) + len(all_fallback)\n",
    "    if total_valid == 0:\n",
    "        print(\"HATA: Hiç geçerli veri bulunamadı.\")\n",
    "        return\n",
    "\n",
    "    coverage_ratio = (len(all_covered) / total_valid) * 100\n",
    "    rmse_cf = np.sqrt(np.mean(all_covered)) if all_covered else 0\n",
    "    rmse_fb = np.sqrt(np.mean(all_fallback)) if all_fallback else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Total Instances:     {total_valid}\")\n",
    "    print(f\"Covered by CF:       {len(all_covered)}\")\n",
    "    print(f\"COVERAGE RATIO:      {coverage_ratio:.2f}% \")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"RMSE (Pure CF):      {rmse_cf:.4f}\")\n",
    "    print(f\"RMSE (Fallback):     {rmse_fb:.4f}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Çalıştır\n",
    "analyze_anhui_global_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4fbcdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanı Başlıyor... Toplam Dönem Sayısı: 7\n",
      "\n",
      "--- Transition to Sem 2 ---\n",
      "Train Unique Courses: 8\n",
      "Test Unique Courses:  9\n",
      "OVERLAP (Intersection): 0\n",
      "⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\n",
      "\n",
      "--- Transition to Sem 3 ---\n",
      "Train Unique Courses: 17\n",
      "Test Unique Courses:  8\n",
      "OVERLAP (Intersection): 0\n",
      "⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\n",
      "\n",
      "--- Transition to Sem 4 ---\n",
      "Train Unique Courses: 25\n",
      "Test Unique Courses:  7\n",
      "OVERLAP (Intersection): 0\n",
      "⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\n",
      "\n",
      "--- Transition to Sem 5 ---\n",
      "Train Unique Courses: 32\n",
      "Test Unique Courses:  6\n",
      "OVERLAP (Intersection): 0\n",
      "⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\n",
      "\n",
      "--- Transition to Sem 6 ---\n",
      "Train Unique Courses: 38\n",
      "Test Unique Courses:  8\n",
      "OVERLAP (Intersection): 0\n",
      "⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\n",
      "\n",
      "--- Transition to Sem 7 ---\n",
      "Train Unique Courses: 46\n",
      "Test Unique Courses:  4\n",
      "OVERLAP (Intersection): 0\n",
      "⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\n"
     ]
    }
   ],
   "source": [
    "def diagnose_data_overlap():\n",
    "    sorted_semesters = sorted(set(df.iloc[:, 4]))\n",
    "    print(f\"Tanı Başlıyor... Toplam Dönem Sayısı: {len(sorted_semesters)}\")\n",
    "    \n",
    "    for sem_idx in range(1, len(sorted_semesters)):\n",
    "        curr_sem = sorted_semesters[sem_idx]\n",
    "        prev_sems = sorted_semesters[:sem_idx]\n",
    "        \n",
    "        # 1. Eğitimdeki Dersleri Topla\n",
    "        train_courses = set()\n",
    "        for ps in prev_sems:\n",
    "            # df.iloc[:, 4] == semester, df.iloc[:, 1] == course_title\n",
    "            courses = df[df.iloc[:, 4] == ps].iloc[:, 1].unique()\n",
    "            train_courses.update(courses)\n",
    "            \n",
    "        # 2. Testteki Dersleri Topla\n",
    "        test_courses = set(df[df.iloc[:, 4] == curr_sem].iloc[:, 1].unique())\n",
    "        \n",
    "        # 3. Kesişime Bak\n",
    "        intersection = train_courses.intersection(test_courses)\n",
    "        \n",
    "        print(f\"\\n--- Transition to Sem {curr_sem} ---\")\n",
    "        print(f\"Train Unique Courses: {len(train_courses)}\")\n",
    "        print(f\"Test Unique Courses:  {len(test_courses)}\")\n",
    "        print(f\"OVERLAP (Intersection): {len(intersection)}\")\n",
    "        \n",
    "        if len(intersection) == 0:\n",
    "            print(\"⚠️ KRİTİK: Hiç ortak ders yok! CF çalışamaz.\")\n",
    "\n",
    "diagnose_data_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d559b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Dönem Sayısı: 7\n",
      "\n",
      "--- Test Dönemi: 2 ---\n",
      "Eğitim Setindeki Ders Sayısı: 8\n",
      "Test Setindeki Ders Sayısı:   9\n",
      "ORTAK DERS SAYISI (Overlap):  0\n",
      "❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\n",
      "\n",
      "--- Test Dönemi: 3 ---\n",
      "Eğitim Setindeki Ders Sayısı: 17\n",
      "Test Setindeki Ders Sayısı:   8\n",
      "ORTAK DERS SAYISI (Overlap):  0\n",
      "❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\n",
      "\n",
      "--- Test Dönemi: 4 ---\n",
      "Eğitim Setindeki Ders Sayısı: 25\n",
      "Test Setindeki Ders Sayısı:   7\n",
      "ORTAK DERS SAYISI (Overlap):  0\n",
      "❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\n",
      "\n",
      "--- Test Dönemi: 5 ---\n",
      "Eğitim Setindeki Ders Sayısı: 32\n",
      "Test Setindeki Ders Sayısı:   6\n",
      "ORTAK DERS SAYISI (Overlap):  0\n",
      "❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\n",
      "\n",
      "--- Test Dönemi: 6 ---\n",
      "Eğitim Setindeki Ders Sayısı: 38\n",
      "Test Setindeki Ders Sayısı:   8\n",
      "ORTAK DERS SAYISI (Overlap):  0\n",
      "❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\n",
      "\n",
      "--- Test Dönemi: 7 ---\n",
      "Eğitim Setindeki Ders Sayısı: 46\n",
      "Test Setindeki Ders Sayısı:   4\n",
      "ORTAK DERS SAYISI (Overlap):  0\n",
      "❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\n"
     ]
    }
   ],
   "source": [
    "def check_course_overlap():\n",
    "    sorted_semesters = sorted(set(df.iloc[:, 4])) # Dönemleri sırala\n",
    "    print(f\"Toplam Dönem Sayısı: {len(sorted_semesters)}\")\n",
    "    \n",
    "    # Her bir test dönemi için kontrol et\n",
    "    for i in range(1, len(sorted_semesters)):\n",
    "        current_sem = sorted_semesters[i] # Test Dönemi (Örn: Dönem 2)\n",
    "        \n",
    "        # Geçmişteki TÜM dönemleri topla (Train)\n",
    "        past_semesters = sorted_semesters[:i] \n",
    "        \n",
    "        # 1. Geçmişteki (Train) Derslerin Listesi\n",
    "        # df.iloc[:, 4] -> Dönem No, df.iloc[:, 1] -> Ders Adı\n",
    "        train_courses = set(df[df.iloc[:, 4].isin(past_semesters)].iloc[:, 1].unique())\n",
    "        \n",
    "        # 2. Şu anki (Test) Derslerin Listesi\n",
    "        test_courses = set(df[df.iloc[:, 4] == current_sem].iloc[:, 1].unique())\n",
    "        \n",
    "        # 3. Kesişim (Overlap)\n",
    "        common_courses = train_courses.intersection(test_courses)\n",
    "        \n",
    "        print(f\"\\n--- Test Dönemi: {current_sem} ---\")\n",
    "        print(f\"Eğitim Setindeki Ders Sayısı: {len(train_courses)}\")\n",
    "        print(f\"Test Setindeki Ders Sayısı:   {len(test_courses)}\")\n",
    "        print(f\"ORTAK DERS SAYISI (Overlap):  {len(common_courses)}\")\n",
    "        \n",
    "        if len(common_courses) == 0:\n",
    "            print(\"❌ SONUÇ: Ortak ders yok -> CF Tahmin Üretemez -> Coverage %0 olur.\")\n",
    "        else:\n",
    "            print(f\"✅ SONUÇ: {len(common_courses)} adet ortak ders var -> Tahmin yapılabilir.\")\n",
    "\n",
    "check_course_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a44883f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Öğrencileri: 382\n",
      "Test Öğrencileri: 382\n",
      "Ortak Öğrenciler: 382\n",
      "\n",
      "Örnek Öğrenci 0:\n",
      "  Train Dersleri: ['Ideological and Moral Cultivation and Legal Foundation', 'Success: Career Planning', 'Introduction to Computer Science', 'Advanced Mathematics A(1)', 'College English A(1)', 'University Chinese', 'Mental Health Education for College Students', 'Ideological and Political Theory Course Practice1']\n",
      "  Test Dersleri: ['C/C++ Language Programming', 'C/C++ Language Programming Course Design', 'Digital Logic Circuits', 'Introduction to the Basic Principles of Marxism', 'Basic Education for Entrepreneurship', 'Higher Mathematics A(2)', 'Cognitive Internship (IT Basic Training)', 'Ideological and Political Theory Course Practice2', 'College English A(2)']\n",
      "  Ortak Dersler: set()\n"
     ]
    }
   ],
   "source": [
    "def debug_coverage():\n",
    "    sorted_semesters = sorted(set(df.iloc[:, 4]))\n",
    "    \n",
    "    # Basit durum: İlk 2 dönem\n",
    "    train_semester = get_semester_data(sorted_semesters[0])\n",
    "    test_semester = get_semester_data(sorted_semesters[1])\n",
    "    \n",
    "    print(f\"Train Öğrencileri: {len(train_semester)}\")\n",
    "    print(f\"Test Öğrencileri: {len(test_semester)}\")\n",
    "    \n",
    "    # Kesişim\n",
    "    common_students = set(train_semester.keys()).intersection(set(test_semester.keys()))\n",
    "    print(f\"Ortak Öğrenciler: {len(common_students)}\")\n",
    "    \n",
    "    if len(common_students) > 0:\n",
    "        sample_student = list(common_students)[0]\n",
    "        print(f\"\\nÖrnek Öğrenci {sample_student}:\")\n",
    "        print(f\"  Train Dersleri: {list(train_semester[sample_student].keys())}\")\n",
    "        print(f\"  Test Dersleri: {list(test_semester[sample_student].keys())}\")\n",
    "        print(f\"  Ortak Dersler: {set(train_semester[sample_student].keys()).intersection(set(test_semester[sample_student].keys()))}\")\n",
    "\n",
    "debug_coverage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Student Grade)",
   "language": "python",
   "name": "student_grade_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
